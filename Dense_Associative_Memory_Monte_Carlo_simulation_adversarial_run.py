import numpy as np
import jax
import matplotlib.pyplot as plt
jax.config.update("jax_enable_x64", True)

from Dense_Associative_Memory_Monte_Carlo_simulation import *

def adversarial_run(p, T_s, seed, N, L, t_s, t, max_adv_overlap = False):
    '''
    Run Monte-Carlo simulations for p_s = 2 and a predefined range of epsilon and alpha to reproduce Fig. (8).
    The results are saved in .npy files.
    
    Inputs
    ------
    p (int):
        Interaction order of the student network.
    T_s (float):
        Temperature of the teacher network.
    seed (int):
        User-defined seed for random number generation.
    N (int):
        Number of entries in the patterns memorized by the student network and generated by the teacher network.
    L (int):
        Number of patterns sampled from the student network.
    t_s (int):
        Number of Monte-Carlo steps for the teacher network.
    t (int):
        Number of Monte-Carlo steps for the student network.
    max_adv_overlap (bool):
        Whether the student pattern is corrupted by the memory that has the largest overlap with it.
        If max_adv_overlap == False, then the student pattern is corrupted by a typical memory.
    
    Outputs
    -------
    None
    '''
    p_s = 2
    beta_s = 1/T_s
    beta = np.inf
    
    n_eps = 25
    n_alpha = 25
    
    eps_range = np.linspace(0.25, 0.5, num = n_eps, endpoint = True)
    alpha_range = np.linspace(0.05, 1, num = n_alpha, endpoint = True)
    
    M = int(np.max(alpha_range) * N**(p/2)/np.math.factorial(p/2+1))
    
    key = jax.random.PRNGKey(seed)
    key_teacher, key_student, key_adv = jax.random.split(key, num = 3)
    
    mean_xi_overlaps = np.zeros((n_eps, n_alpha))
    std_xi_overlaps = np.zeros((n_eps, n_alpha))
    
    teacher_init_overlap = 0
    student_init_overlap = 1
    
    teacher_batch_size = int(np.sqrt(N))
    student_batch_size = 1
    
    teacher = Model("gardner", p_s, N, 1, M, teacher_batch_size, key_teacher)
    student = Model("gardner", p, N, M, L, student_batch_size, key_student)
    
    xi_s_spins = None
    
    xi_s_spins, sigma_spins = teacher.init_spins(teacher_init_overlap, ori_spins = xi_s_spins)
    
    sigma_spins = teacher.generate_spins(t_s, beta_s, xi_s_spins, sigma_spins)
    # print("Teacher done")
    
    if max_adv_overlap:
        sigma_overlaps = np.squeeze((xi_s_spins @ sigma_spins)/N)
    else:
        sigma_overlaps = np.abs(np.squeeze((xi_s_spins @ sigma_spins)/N))
    
    for j, alpha in enumerate(alpha_range):
        M = int(alpha * N**(p/2)/np.math.factorial(p/2+1))
    
        sigma_spins_slice = sigma_spins.T[: M]
        
        if max_adv_overlap:
            k = np.argmax(sigma_overlaps[: M])
        else:
            k = np.argmin(sigma_overlaps[: M])
        
        adv_spins = sigma_spins_slice[k]
        
        for i, eps in enumerate(eps_range):
            
            key_adv, key_atk = jax.random.split(key_adv)
            mask_adv = jax.random.choice(key_atk, jax.numpy.array([0, 1], dtype = "float32"), (L, N), p = jax.numpy.array([1 - eps, eps]))
            
            ori_spins = (1 - mask_adv) * xi_s_spins + mask_adv * adv_spins
            
            ori_spins, xi_spins = student.init_spins(student_init_overlap, ori_spins = ori_spins)
            
            xi_spins = student.generate_spins(t, beta, sigma_spins_slice, xi_spins)
            # print("Student done")
            xi_overlaps = (xi_s_spins @ xi_spins)/N
            mean_xi_overlaps[i, j] = np.mean(xi_overlaps)
            std_xi_overlaps[i, j] = np.std(xi_overlaps)
    
    with open("./Data/overlaps/mean_xi_overlap_adversarial_max_adv_overlap=%s_p=%d.npy" % (max_adv_overlap, p), "wb") as file:
        np.save(file, mean_xi_overlaps)
    
    with open("./Data/overlaps/std_xi_overlap_adversarial_max_adv_overlap=%s_p=%d.npy" % (max_adv_overlap, p), "wb") as file:
        np.save(file, std_xi_overlaps)